BERT-NER结构实现文本断句和标点符号预测功能。

### 数据
作者使用了一些小说当作训练数据，使用类似BIO的NER格式自动标注。

原始语料放在*data/raw/* 下面

使用*data_helper* 可以分别生成断句的语料和标点的训练语料。

### 模型训练

由于时间有点久远，作者搞忘了有没有把标点和断句合并一起训练，*run_ner.py* 中很简单能找到实现逻辑。

由于模型比较小，设备好的朋友梯度积累完全没有必要，fp16混合精度也是，多机多卡也没必要。。。

最简单开启模型训练 train.sh

### 推理与预测
见*predict.py*

toy_model: 链接: https://pan.baidu.com/s/1UkHW8sviqCeCtIBuUxGhJA  密码: pmmb

### 成品模型与应用

见我的另外一个repo: https://github.com/zhiyou720/nlp_preprocess

### 其他

1. 括号类成对标点:

一开始我想的比较简单，对于这种标点的标注方式也跟普通一样，但其实这类的标注方式用完成BIO形式标注效果肯定会特别好，有兴趣的可以自己尝试。

2. 标点符号的预测用BERT有长度限制，这点就很烦。可以考虑GPT类生成模型做。


